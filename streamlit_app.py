# -*- coding: utf-8 -*-
"""streamlit_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GECWkHmjft2EoID9U4dLcgJADrWGSfab
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import requests
from bs4 import BeautifulSoup

# Function to scrape GDP data
def get_gdp_data(source):
    url = "https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    tables = soup.find_all('table', {'class': 'wikitable'})

    source_index = {"IMF": 0, "UN": 1, "World Bank": 2}
    table = tables[source_index[source]]

    data = []
    for row in table.find_all('tr')[1:]:
        cols = row.find_all('td')
        if len(cols) > 1:
            country = cols[0].text.strip()
            gdp = cols[1].text.strip().replace(',', '')
            try:
                gdp = float(gdp)
            except ValueError:
                continue
            data.append([country, gdp])

    return pd.DataFrame(data, columns=["Country", "GDP"])

# Function to scrape region data (moved outside app_code)
def get_region_data():
    url = 'https://www.ucl.ac.uk/global/regional-activity/countries-and-regions-directory'
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    region_tables = soup.find_all('td')

    data = []
    for i in range(0, len(region_tables), 2):
        country = region_tables[i].text.split(";")[0].strip()
        region = region_tables[i + 1].text.strip()
        data.append((country, region))

    return pd.DataFrame(data, columns=["Country", "Region"])

# Streamlit app code as a string
app_code = """
import streamlit as st
import plotly.express as px
import pandas as pd

""" # Define app_code with the Streamlit code as a string

st.title("Global GDP Stacked Bar Chart")

gdp_source = st.selectbox("Select GDP Data Source", ["IMF", "UN", "World Bank"])
df_gdp = get_gdp_data(gdp_source)
df_region = get_region_data()

# Merge data
df = df_gdp.merge(df_region, on="Country", how="left").dropna()

# Create plot
df_sorted = df.sort_values(by=["Region", "GDP"], ascending=[True, False])
fig = px.bar(df_sorted, x="Region", y="GDP", color="Country", title=f"GDP by Country (Source: {gdp_source})", labels={"GDP": "GDP (in USD)"}, height=600)

st.plotly_chart(fig)


# Save the Streamlit app code to a file
with open("app.py", "w") as f:
    f.write(app_code)

# Configure ngrok with your authtoken
conf.get_default().auth_token = "2tjpGMZXMCMlFPLTAxDXTRG9IXK_3YJZNS7stsxCAugRJ7hb4"  # Replace with your actual authtoken

# Use ngrok to open a tunnel for the Streamlit app
public_url = ngrok.connect(8501) # Changed '8501' to 8501


# Run the Streamlit app in the background
!streamlit run app.py &
# Install necessary packages if not already installed
!pip install streamlit pyngrok

import streamlit as st
import pandas as pd
import plotly.express as px
import requests
from bs4 import BeautifulSoup
# Import ngrok
from pyngrok import ngrok, conf

# Function to scrape GDP data
def get_gdp_data(source):
    url = "https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    tables = soup.find_all('table', {'class': 'wikitable'})

    source_index = {"IMF": 0, "UN": 1, "World Bank": 2}
    table = tables[source_index[source]]

    data = []
    for row in table.find_all('tr')[1:]:
        cols = row.find_all('td')
        if len(cols) > 1:
            country = cols[0].text.strip()
            gdp = cols[1].text.strip().replace(',', '')
            try:
                gdp = float(gdp)
            except ValueError:
                continue
            data.append([country, gdp])

    return pd.DataFrame(data, columns=["Country", "GDP"])

# Function to scrape region data (moved outside app_code)
def get_region_data():
    url = 'https://www.ucl.ac.uk/global/regional-activity/countries-and-regions-directory'
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    region_tables = soup.find_all('td')

    data = []
    for i in range(0, len(region_tables), 2):
        country = region_tables[i].text.split(";")[0].strip()
        region = region_tables[i + 1].text.strip()
        data.append((country, region))

    return pd.DataFrame(data, columns=["Country", "Region"])

# Streamlit app code as a string
app_code = """
import streamlit as st
import plotly.express as px
import pandas as pd

""" # Define app_code with the Streamlit code as a string

st.title("Global GDP Stacked Bar Chart")

gdp_source = st.selectbox("Select GDP Data Source", ["IMF", "UN", "World Bank"])
df_gdp = get_gdp_data(gdp_source)
df_region = get_region_data()

# Merge data
df = df_gdp.merge(df_region, on="Country", how="left").dropna()

# Create plot
df_sorted = df.sort_values(by=["Region", "GDP"], ascending=[True, False])
fig = px.bar(df_sorted, x="Region", y="GDP", color="Country", title=f"GDP by Country (Source: {gdp_source})", labels={"GDP": "GDP (in USD)"}, height=600)

st.plotly_chart(fig)


# Save the Streamlit app code to a file
with open("app.py", "w") as f:
    f.write(app_code)

# Configure ngrok with your authtoken
conf.get_default().auth_token = "2tjpGMZXMCMlFPLTAxDXTRG9IXK_3YJZNS7stsxCAugRJ7hb4"  # Replace with your actual authtoken

# Use ngrok to open a tunnel for the Streamlit app
public_url = ngrok.connect(8501) # Changed '8501' to 8501


# Run the Streamlit app in the background
!streamlit run app.py &

# Kills previous tunnels (optional, you can keep this)
# Install necessary packages if not already installed
!pip install streamlit pyngrok

import streamlit as st
import pandas as pd
import plotly.express as px
import requests
from bs4 import BeautifulSoup
# Import ngrok
from pyngrok import ngrok, conf

# Function to scrape GDP data
def get_gdp_data(source):
    url = "https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    tables = soup.find_all('table', {'class': 'wikitable'})

    source_index = {"IMF": 0, "UN": 1, "World Bank": 2}
    table = tables[source_index[source]]

    data = []
    for row in table.find_all('tr')[1:]:
        cols = row.find_all('td')
        if len(cols) > 1:
            country = cols[0].text.strip()
            gdp = cols[1].text.strip().replace(',', '')
            try:
                gdp = float(gdp)
            except ValueError:
                continue
            data.append([country, gdp])

    return pd.DataFrame(data, columns=["Country", "GDP"])

# Function to scrape region data (moved outside app_code)
def get_region_data():
    url = 'https://www.ucl.ac.uk/global/regional-activity/countries-and-regions-directory'
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    region_tables = soup.find_all('td')

    data = []
    for i in range(0, len(region_tables), 2):
        country = region_tables[i].text.split(";")[0].strip()
        region = region_tables[i + 1].text.strip()
        data.append((country, region))

    return pd.DataFrame(data, columns=["Country", "Region"])

# Streamlit app code as a string
app_code = """
import streamlit as st
import plotly.express as px
import pandas as pd

""" # Define app_code with the Streamlit code as a string

# ... [rest of your code] ...

# Save the Streamlit app code to a file
with open("app.py", "w") as f:
    f.write(app_code)
